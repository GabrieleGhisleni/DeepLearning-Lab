{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab5_AnimeGAN","provenance":[{"file_id":"17I9n-kFZCUaNYTiMRdbt0dxsBDwNR2en","timestamp":1646048063947}],"collapsed_sections":[],"authorship_tag":"ABX9TyOB014SuXa3ndQsFjjxPldU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Generative Adversarial Networks (GANs)\n","\n","The GAN architecture consists of a **generator** network and a **discriminator** network. The former is in charge of generating synthetic images from noise, in order to fool the discriminator. On the other hand, the discriminator network is in charge of telling apart real images from fake ones. This leads to a two player **mini-max adversarial game** between the two. Through this optimization, the generator learns to produce photo-realistic images, similar to the real data.\n","\n","![Alexnet architecture](https://www.researchgate.net/publication/343597759/figure/fig4/AS:923532934529034@1597198818441/The-architecture-of-the-generator-and-the-discriminator-in-a-DCGAN-model-FSC-is-the.ppm)\n","\n","In this lab session we will learn how to code a GAN to generate anime faces from noise inputs. Let's start by importing, as usual, the necessary modules."],"metadata":{"id":"26RC3kFttoJY"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.datasets as dset\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import torch.optim as optim\n","from torchvision.utils import save_image"],"metadata":{"id":"H7gaPmJMuA93"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's mount the Google Drive folder into our colab environment"],"metadata":{"id":"Sq6wYVQxueP5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"AglapVs6uLbS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We need the [tar](https://drive.google.com/file/d/1PrLr4jwkIwHxQJvQaKJNxw5yAReFpJnA/view?usp=sharing) archive in our Google Drive storage (you can do this by simply creating a shortcut by following the link). We will then extract the files. Please change the paths according to your directory structure of Google Drive"],"metadata":{"id":"L_PNHWRZuQh3"}},{"cell_type":"code","source":["# specify the path of the tar in your gdrive\n","% cp \"/content/gdrive/My Drive/datasets/anime-faces.tar.gz\" ./"],"metadata":{"id":"iZt8t_38u0HV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's extract!"],"metadata":{"id":"8dqPOoojvLCe"}},{"cell_type":"code","source":["! tar -xf anime-faces.tar.gz"],"metadata":{"id":"Gdw4uLg3u4rC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now need to define some constants that we will use in our implementation"],"metadata":{"id":"u8FsB6kRvQ6X"}},{"cell_type":"code","source":["img_size = 64\n","root_folder = \"/content/anime-faces/\"\n","batch_size = 128\n","nc = 3 # number of channels in an image (RGB)\n","ngf = 64 # number of features in the generator\n","ndf = 64 # number of channels in the discriminator\n","nz = 100 # dimension of the latent space\n","lr = 0.0002 # learning rate for the networks\n","num_epochs = 100 # total number of training epochs\n","save_dir = \"/gan_log/\""],"metadata":{"id":"5_5LqDdmvPXb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For visualization purposes, we will now sample some items from our dataset"],"metadata":{"id":"dpFEi5Vwvd30"}},{"cell_type":"code","source":["# create a set of transforms for the dataset\n","dset_transforms = list()\n","dset_transforms.append(transforms.Resize(img_size))\n","dset_transforms.append(transforms.ToTensor())\n","dset_transforms.append(transforms.Normalize(mean=[0.5, 0.5, 0.5], \n","                                            std=[0.5, 0.5, 0.5]))\n","dset_transforms = transforms.Compose(dset_transforms)\n","\n","# create a dataset using ImageFolder of pytorch\n","dataset = dset.ImageFolder(root=root_folder, transform=dset_transforms)\n","\n","# create a data loader\n","dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4,\n","                        shuffle=True, drop_last=True)\n","\n","# Plot images\n","fixed_batch = next(iter(dataloader))  # Gets the first batch\n","plt.figure(figsize=(8, 8))\n","plt.axis(\"off\")\n","plt.title(\"Training images\")\n","plt.imshow(np.transpose(vutils.make_grid(fixed_batch[0][:64], padding=2, \n","                                         normalize=True), (1, 2, 0)))"],"metadata":{"id":"TrEYQ5QavaB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now proceed into a custom initialization of the weights for our generator and discriminator."],"metadata":{"id":"SFfOU-oLvt07"}},{"cell_type":"code","source":["def weight_init(m):\n","  classname = m.__class__.__name__\n","  if classname.find('Conv') != -1:\n","    nn.init.normal_(m.weight.data, 0.0, 0.02)\n","  elif classname.find('BatchNorm') != -1:\n","    nn.init.normal_(m.weight.data, 1.0, 0.02)\n","    nn.init.constant_(m.bias.data, 0.0)"],"metadata":{"id":"FgiKKVbXvmIN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generator\n","In the upcoming code block, we will define our generator according to the DCGAN fashion. If interested, you may take a look at the [original paper](https://arxiv.org/abs/1511.06434)."],"metadata":{"id":"FhwRfT7Uv7ha"}},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self):\n","    super(Generator, self).__init__()\n","\n","    self.main = nn.Sequential(\n","        nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8,\n","                           kernel_size=(4, 4), stride=1, padding=0,\n","                           bias=False),\n","        nn.BatchNorm2d(num_features=ngf * 8),\n","        nn.ReLU(inplace=True),\n","\n","        nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4,\n","                           kernel_size=(4, 4), stride=2, padding=1,\n","                           bias=False),\n","        nn.BatchNorm2d(num_features=ngf * 4),\n","        nn.ReLU(inplace=True),\n","\n","        nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2,\n","                           kernel_size=(4, 4), stride=2, padding=1,\n","                           bias=False),\n","        nn.BatchNorm2d(num_features=ngf * 2),\n","        nn.ReLU(inplace=True),\n","\n","        nn.ConvTranspose2d(in_channels=ngf * 2, out_channels=ngf,\n","                           kernel_size=(4, 4), stride=2, padding=1,\n","                           bias=False),\n","        nn.BatchNorm2d(num_features=ngf),\n","        nn.ReLU(inplace=True),\n","\n","        nn.ConvTranspose2d(in_channels=ngf, out_channels=nc,\n","                           kernel_size=(4, 4), stride=2, padding=1,\n","                           bias=False),\n","        nn.Tanh()\n","    )\n","  \n","  def forward(self, x):\n","    out = self.main(x)\n","    return out "],"metadata":{"id":"eDN-9eQTv4Jy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's apply the custom initialization to our generator, and print its structure."],"metadata":{"id":"-lf4peB0wl2c"}},{"cell_type":"code","source":["netG = Generator().cuda()\n","netG.apply(weight_init)\n","print(netG)"],"metadata":{"id":"IJkG97RtwjLq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Discriminator\n","\n","The discriminator is a network meant to address the binary classification task of distinguishing whether a given input image is fake or real."],"metadata":{"id":"N3v2oCtPw67l"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    \n","    self.main = nn.Sequential(\n","        nn.Conv2d(in_channels=nc, out_channels=ndf, kernel_size=(4, 4),\n","                  stride=2, padding=1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","\n","        nn.Conv2d(in_channels=ndf, out_channels=ndf * 2, kernel_size=(4, 4),\n","                  stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(num_features=ndf * 2),\n","        nn.LeakyReLU(0.2, inplace=True),\n","\n","        nn.Conv2d(in_channels=ndf * 2, out_channels=ndf * 4, kernel_size=(4, 4),\n","                  stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(num_features=ndf * 4),\n","        nn.LeakyReLU(0.2, inplace=True),\n","\n","        nn.Conv2d(in_channels=ndf * 4, out_channels=ndf * 8, kernel_size=(4, 4),\n","                  stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(num_features=ndf * 8),\n","        nn.LeakyReLU(0.2, inplace=True),\n","\n","        nn.Conv2d(in_channels=ndf * 8, out_channels=1, kernel_size=(4, 4),\n","                  stride=1, padding=0, bias=False),\n","        nn.Sigmoid()\n","    )\n","\n","  def forward(self, x):\n","    out = self.main(x)\n","    return out"],"metadata":{"id":"TDWVZDhCwtWW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's initialize and print."],"metadata":{"id":"Rbr6-I9pxIMF"}},{"cell_type":"code","source":["netD = Discriminator().cuda()\n","netD.apply(weight_init)\n","print(netD)"],"metadata":{"id":"wFcoHJSuxEUo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training setup\n","\n","We will now lay out our training setting, defining the ingredients that we need."],"metadata":{"id":"DswLg8vwxNP-"}},{"cell_type":"code","source":["# define the loss criterion\n","criterion = nn.BCELoss()\n","\n","# sample a fixed noise vector that will be used to visualize the training\n","# progress\n","fixed_noise = torch.randn(64, nz, 1, 1).cuda()\n","\n","# define the ground truth labels.\n","real_labels = 1.0 # for the real images\n","fake_labels = 0.0 # for the fake images\n","\n","# define the optimizers, one for each network\n","netD_optimizer = optim.Adam(params=netD.parameters(), lr=lr, betas=(0.5, 0.999))\n","netG_optimizer = optim.Adam(params=netG.parameters(), lr=lr, betas=(0.5, 0.999))\n","\n","# sample two fixed noise vectors and do a linear interpolation between them\n","# to get the intermediate noise vectors. We will generate samples for the interpolated\n","# noise vectors to see effect of interpolation in the latent space (see later!)\n","z_1 = torch.randn(1, nz, 1, 1)\n","z_2 = torch.randn(1, nz, 1, 1)\n","fixed_interpolate = []\n","for i in range(64):\n","  lambda_interp = i / 63\n","  z_interp = z_1 * (1 - lambda_interp) + lambda_interp * z_2\n","  fixed_interpolate.append(z_interp)\n","# fixed_interpolate is (64, nz, 1, 1)\n","fixed_interpolate = torch.cat(fixed_interpolate, dim=0).cuda()"],"metadata":{"id":"fPAGaiXjxKpt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Put it all together\n","\n","We will now create our main function in order to carry out the actual GAN training."],"metadata":{"id":"bnra9qvqxrCv"}},{"cell_type":"code","source":["def main():\n","\n","  # iterations counter\n","  iters = 0\n","\n","  # iterate over the number of epochs\n","  for epoch in range(num_epochs):\n","\n","    # iterate over the data loader\n","    for i, data in enumerate(dataloader, 0):\n","      \n","      ## Discriminator training ##\n","      # maximize log(D(x)) + log(1 - D(G(x)))\n","\n","      # The discriminator will be updated once with the real images\n","      # and once with the fake images. This is achieved by first computing\n","      # the gradients with the real images (the first term in the D loss function),\n","      # and then with the fake images generated by the G (second loss term).\n","      # Only after that the optimizer.step() will be done, which will update the\n","      # weights of the D.\n","      # IMPORTANT to note that when the D is updated, the G is kept frozen.\n","      # Gradients are calculated with loss.backward().\n","\n","      # train D with real images\n","      netD.train()\n","\n","      # zero the gradients of the discriminator\n","      netD.zero_grad()\n","\n","      # data is a Tuple (images, labels). We only need the images\n","      real_images = data[0].cuda() \n","      bs = real_images.shape[0]\n","      \n","      # we train the discriminator labelling these as real images\n","      label = torch.full((bs,), real_labels).cuda()\n","      output = netD(real_images).view(-1)\n","\n","      # calculate loss on real images. This encourages D to output 1 for\n","      # real images\n","      errD_real = criterion(output, label)\n","\n","      # calculate gradients for D\n","      errD_real.backward()\n","\n","      # track D outputs for real images\n","      D_x = output.mean().item()\n","\n","      # train D with fake images: sample a batch of noise vectors\n","      noise = torch.randn(bs, nz, 1, 1).cuda()\n","\n","      # generate fake data\n","      fake_images = netG(noise)\n","\n","      # we train the discriminator labelling these as fake images\n","      label.fill_(fake_labels)\n","\n","      # run the fake images through the discriminator. \n","      # IMPORTANT to detach the fake_images because we do not need gradients\n","      # of the G activations wrt to the G weights.\n","      output = netD(fake_images.detach()).view(-1)\n","      \n","      # calculate loss on the fake images. This encourages D to output 0 for\n","      # fake images\n","      errD_fake = criterion(output, label)\n","\n","      # calculate the gradients for D\n","      # Note that gradients are not reset between backward() calls, so gradients\n","      # are summed to the ones computed for real images\n","      errD_fake.backward()\n","      errD = (errD_real + errD_fake)\n","\n","      # track D outputs for fake images\n","      D_G_x_1 = output.mean().item()\n","\n","      # update the D weights with the gradients accumulated\n","      netD_optimizer.step()\n","\n","      ## Generator training ##\n","      # minimize log(1 - D(G(x)))\n","      # But such a formulation provides no gradient during the early stages of\n","      # training and hence its is reformulated as:\n","      # maximize log(D(G(x)))\n","\n","      # during the G training the discriminator D is kept fixed\n","      netG.train()\n","      netG.zero_grad()\n","\n","      # we want to train G to confuse D, so we instatiate the loss between\n","      # the output of D when called on a fake image and a vector filled with\n","      # real labels. This way, G is encouraged to produce fake images in such\n","      # a way as to push D to output 1, i.e. fooling D into believing\n","      # that the images are real\n","      label.fill_(real_labels)\n","      output = netD(fake_images).view(-1)\n","      errG = criterion(output, label)\n","\n","      # calculate the gradients for G\n","      errG.backward()\n","\n","      # track the outputs for fake images\n","      D_G_x_2 = output.mean().item()\n","\n","      # update the G weights with the gradients accumulated\n","      netG_optimizer.step()\n","\n","      # print the training losses\n","      if iters % 100 == 0:\n","        print('[%3d/%d][%3d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' % (epoch, \n","            num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_x_1, D_G_x_2))\n","      \n","      # visualize the samples generated by the generatore. \n","      # 'gan_log/out' and 'gan_log/interpolate' folders stores the generated \n","      # images on fixed_noise and fixed_interpolate noise vectors, respectively\n","      if (iters % 500 == 0) or (epoch == num_epochs - 1):\n","        out_dir = os.path.join(save_dir, 'out/')\n","        os.makedirs(out_dir, exist_ok=True)\n","        interp_dir = os.path.join(save_dir, 'interpolate/')\n","        os.makedirs(interp_dir, exist_ok=True)\n","        netG.eval()\n","        with torch.no_grad():\n","          fake_fixed = netG(fixed_noise).cpu()\n","          save_image(fake_fixed, os.path.join(out_dir, str(iters).zfill(7) + '.png'),\n","                    normalize=True)\n","          \n","          interp_fixed = netG(fixed_interpolate).cpu()\n","          save_image(interp_fixed, os.path.join(interp_dir, str(iters).zfill(7) + '.png'),\n","                    normalize=True)\n","          \n","          # display the images inline as well\n","          fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n","          ax[0].imshow(np.transpose(vutils.make_grid(fake_fixed, padding=2, normalize=True), (1, 2, 0)))\n","          ax[0].axis('off')\n","          ax[0].set_title('Random Samples')\n","\n","          ax[1].imshow(np.transpose(vutils.make_grid(interp_fixed, padding=2, normalize=True), (1, 2, 0)))\n","          ax[1].axis('off')\n","          ax[1].set_title('Interpolations')\n","\n","          plt.show()\n","      \n","      iters += 1"],"metadata":{"id":"W9p8SOjAxoib"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's make it happen!"],"metadata":{"id":"zZrHdPCk17_b"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","  main()"],"metadata":{"id":"nG9XtaaE16gf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LvgL0ZAN1-lA"},"execution_count":null,"outputs":[]}]}