{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.int32, TensorShape([3, 5]), 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tensor are TensorFlowâ€™s built-in multidimensional arrays with uniform type.\n",
    "\n",
    "tensor = tf.constant([\n",
    "    [0,2,3,1,3],\n",
    "    [5,2,3,1,3],\n",
    "    [0,2,2,1,3],\n",
    "])\n",
    "\n",
    "tensor.dtype, tensor.shape, tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "TensorFlow model accepts several object types, which can be listed as follows:\n",
    "\n",
    "- TensorFlow Dataset object\n",
    "- TensorFlow Datasets catalog\n",
    "- NumPy array object\n",
    "- Pandas DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "ds = tf.data.Dataset.from_tensor_slices(numpy_array)\n",
    "ds = tf.data.Dataset.from_tensor_slices(df.values)\n",
    "ds = tf.data.TFRecordDataset(\"file.tfrecord\")\n",
    "ds = tf.data.experimental.make_csv_dataset(\"file.csv\", batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# TF has many already prepared datasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#  Also from Keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.mnist.load_data( path=\"mnist.npz\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras API under TensorFlow 2.x provides three different methods to implement neural network models:\n",
    "\n",
    "- Sequential API\n",
    "- Functional API\n",
    "- Model Subclassing\n",
    "\n",
    "The Keras Sequential API allows you to build a neural network step-by step fashion. You can create a Sequential() model object, and you can add a layer at each line.Using the Keras Sequential API is the easiest method to build models which comes at a cost: limited customization. Although you can build a Sequential model within seconds, Sequential models do not provide some of the functionalities such as (i) layer sharing, (ii) multiple branches, (iii) multiple inputs, and (iv) multiple outputs. A Sequential model is the best option when we have a plain stack of layers with one input tensor and one output tensor.Using the Keras sequential API is the most basic method to build neural networks, which is sufficient for many of the upcoming chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "\n",
    "# Keras API\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128,'relu'),\n",
    "    Dense(10, \"softmax\"),\n",
    "])\n",
    "\n",
    "## Subclassing\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        # super().__init__ very important!\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer_1 = Flatten()\n",
    "        self.layer_2 = Dense(128, \"relu\")\n",
    "        self.layer_3 = Dense(10, \"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # the call function is where the operations are defined\n",
    "        x = self.layer_1(inputs)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return x\n",
    "\n",
    "model = CustomModel(name=' mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling is an import part of the deep learning model training where we define our (i) optimizer, (ii) loss function, and other parameters such as (iii) callbacks.\n",
    "\n",
    "- model.compile()\n",
    "- model.fit()\n",
    "- model.evaluate()\n",
    "- model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam() ,\n",
    "        loss= tf.keras.losses.MSE(),\n",
    "        metrics = [tf.keras.metrics.Accuracy()]\n",
    ")\n",
    "\n",
    "## all optimizers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "## all loss functions: https://www.tensorflow.org/api_docs/python/tf/keras/losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs=50)\n",
    "model.evaluate()\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines show an example of the standard method for training. Just in two lines, you can configure and train your model.\n",
    "model.compile(optimizer=Adam(), loss=SCC(from_logits=True), metrics=[SCA()])\n",
    "model.fit(x_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines, on the other hand, show how you can achieve the same results with a custom training loop.\n",
    "\n",
    "# Instantiate optimizer, loss, and metric\n",
    "optimizer, loss_fn, accuracy = Adam(), SCC(from_logits=True), SCA()\n",
    "# Convert NumPy to TF Dataset object\n",
    "train_dataset = (Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024).batch(batch_size=64))\n",
    "for epoch in range(epochs):\n",
    " # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        # Open a GradientTape to record the operations, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "        # The operations that the layer applies to its inputs are going to be recorded\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            # Use the tape to automatically retrieve the gradients of the trainable variables\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            # Run one step of gradient descent by updatingthe value of the variables to minimize the loss.\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "            # Metrics related part\n",
    "            accuracy.update_state(y_batch_train, logits)\n",
    "            if step % int(len(train_dataset)/5) == 0: #Print out\n",
    "                print(step, \"/\", len(train_dataset),\" | \",end=\"\")\n",
    "            print(\"\\rFor Epoch %.0f, Accuracy: %.4f\" % (epoch+1, float(accuracy.result()),))\n",
    "            accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"My_SavedModel\")\n",
    "reconstructed_model = tf.keras.models.load_model( 'My_SavedModel' )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33dc6d49505b4536b6a128d9d7c879e1fa44477ad44947bbbe73093067fe6393"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
