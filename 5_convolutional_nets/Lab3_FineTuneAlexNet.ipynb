{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3_FineTuneAlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning AlexNet\n",
        "\n",
        "In this lab session we are going to fetch a **pre-trained** version of the [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) architecture, and **fine-tune** it for the task of **object recognition**. In particular, the network has been pre-trained on the [ILSVRC-2012](https://image-net.org/challenges/LSVRC/2012/) dataset which contains more than **1 million** images portraying object belonging to 1000 classes. The code for AlexNet is publicly available [here](https://pytorch.org/hub/pytorch_vision_alexnet/).\n",
        "\n",
        "![Alexnet architecture](https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0106.png)"
      ],
      "metadata": {
        "id": "HVQuq23Q9Hyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Office-Home dataset\n",
        "This dataset contains images belonging to 4 different **domains**, each containing 65 categories. In this particular instance, we are going to use the *Real World* domain. \n",
        "\n",
        "![Office-Home](http://hemanthdv.github.io/profile/images/DataCollage.jpg)"
      ],
      "metadata": {
        "id": "G-UYwRjdM7i8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning pipeline\n",
        "In order to fine-tune our model on this dataset, we will be going through the following steps:\n",
        "1. **discard** the output layer of AlexNet, which is originally structured for 1000 classes\n",
        "2. randomly **initialize** the parameters of a new output layer with output dimensionality equal to the number of classes of our dataset (i.e. 65) using `torch.nn.Linear`. We will keep all other layers untouched\n",
        "3. **train** the network, using a **low** learning rate for the pretrained layers and a **higher** one for the newly defined one"
      ],
      "metadata": {
        "id": "gB6NX35uNssZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount your Google Drive folder on Colab\n",
        "We will store data in our Google Drive account, and copy them to the Colab local drive for our experiment"
      ],
      "metadata": {
        "id": "HjHqVCmmOrqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "B1Yef6sTMr2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset\n",
        "We will now **download** the Office-Home dataset. Please place [this tar file](https://drive.google.com/file/d/1OnhVN2T5sB_Jo2jCbt-IeM5tXYxAlGDF/view?usp=sharing) in your UniTN Google Drive storage. We will then **copy** it to the local Colab drive to **speed up data loading**. First, let's create a directory in our current path; then, we will copy to the local drive and check the content."
      ],
      "metadata": {
        "id": "1geKt8X6PECg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!cp \"gdrive/My Drive/datasets/OfficeHomeDataset.tar\" dataset/\n",
        "!ls dataset"
      ],
      "metadata": {
        "id": "_WMhe-XBO80Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now unzip the tar file"
      ],
      "metadata": {
        "id": "nHy1oBJRQop9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf dataset/OfficeHomeDataset.tar -C dataset\n",
        "!ls dataset"
      ],
      "metadata": {
        "id": "i3ZxhL7JQIQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now get started with the actualy coding. As usual let's start by importing the necessary libraries"
      ],
      "metadata": {
        "id": "sToQmGdCQ3kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "wUPKr_-tQwJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data from the file system\n",
        "We know that PyTorch provides built-in dataset utility for many existing benchmark, but it might often be the case that we still need to access data stored in our local file system. When it comes to images, the toolkit provides a generic `Dataset` class with the [`torchvision.dataset.ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder) module. This class spares us from writing our own custom `Dataset`, but it is important to keep in mind that it assumes the images to be stored in the following fashion:\n",
        "\n",
        "        |\n",
        "        |--- Alarm_Clock\n",
        "        |                \n",
        "        |      |--- 00046.jpg\n",
        "        |      |--- 00050.jpg\n",
        "        |          \n",
        "        |--- Couch\n",
        "               | --- 00007.jpg\n",
        "               | --- 00023.jpg\n",
        "\n",
        "In other words, we are going to have a parent folder (`OfficeHomeDataset`) which contains a sub-folder for each category. Each of these subfolders contains all the images of the dataset corresponding to that category. PyTorch will take care of assigning the labels accordingly at dataloading time."
      ],
      "metadata": {
        "id": "7lvsr7orRH3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "Let's define a method to compactly return the dataloaders that we need, introducing some transformations."
      ],
      "metadata": {
        "id": "jH-orQgISzHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Input arguments:\n",
        "  batch_size: mini batch size used during training\n",
        "  img_root: path to the dataset parent folder. \n",
        "            The folder just above the sub-folders or class folders\n",
        "'''\n",
        "\n",
        "def get_data(batch_size, img_root):\n",
        "  \n",
        "  # prepare data transformations for the train loader\n",
        "  transform = list()\n",
        "  transform.append(T.Resize((256, 256)))                      # resize each PIL image to 256 x 256\n",
        "  transform.append(T.RandomCrop((224, 224)))                  # randomly crop a 224 x 224 patch\n",
        "  transform.append(T.ToTensor())                              # convert Numpy to Pytorch Tensor\n",
        "  transform.append(T.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                               std=[0.229, 0.224, 0.225]))    # normalize with ImageNet mean\n",
        "  transform = T.Compose(transform)                            # compose the above transformations into one\n",
        "    \n",
        "  # load data\n",
        "  officehome_dataset = torchvision.datasets.ImageFolder(root=img_root, transform=transform)\n",
        "  \n",
        "  # create train and test splits (80/20)\n",
        "  num_samples = len(officehome_dataset)\n",
        "  training_samples = int(num_samples * 0.8 + 1)\n",
        "  test_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, test_data = torch.utils.data.random_split(officehome_dataset, \n",
        "                                                           [training_samples, test_samples])\n",
        "\n",
        "  # initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False)\n",
        "  \n",
        "  return train_loader, test_loader"
      ],
      "metadata": {
        "id": "eR7Lwq69RCDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the AlexNet model\n",
        "As previously mentioned, PyTorch provides several models that can optionally be loaded with the parameters trained on ImageNet. If interested, take a look [here](https://pytorch.org/vision/stable/models.html). We will use the `torchvision` library to access the model, and we will then apply the aforementioned modifications. Before that, let's take a look at the original [code](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py). "
      ],
      "metadata": {
        "id": "OHJ4r87wTPdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Input arguments\n",
        "  num_classes: number of classes in the dataset.\n",
        "               This is equal to the number of output neurons.\n",
        "'''\n",
        "\n",
        "def initialize_alexnet(num_classes):\n",
        "\n",
        "  # load the pre-trained Alexnet\n",
        "  alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "  \n",
        "  # get the number of neurons in the second last layer\n",
        "  in_features = alexnet.classifier[6].in_features\n",
        "  \n",
        "  # re-initalize the output layer\n",
        "  alexnet.classifier[6] = torch.nn.Linear(in_features=in_features, \n",
        "                                          out_features=num_classes)\n",
        "  \n",
        "  return alexnet"
      ],
      "metadata": {
        "id": "Xnf6GKJTTNCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now print the description of the model we just instatiated and customized"
      ],
      "metadata": {
        "id": "g--imsbIUN05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(initialize_alexnet(65))"
      ],
      "metadata": {
        "id": "KhuO24auUKcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost function\n",
        "Being this a standard classification task, we opt for a Cross Entropy Loss"
      ],
      "metadata": {
        "id": "k9VNJUkDUW3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ],
      "metadata": {
        "id": "elxESXZMUTGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer\n",
        "Unlike previous cases, where we were using a unique learning rate, in this case we need some additional coding in order to apply the distinction mentioned above according to the involved layers. In particular, the pre-trained layers need to be updated at a lesser rate than the newly initialized layer. Details are available [here](https://pytorch.org/docs/stable/optim.html).\n",
        "\n",
        "In order to achieve what we want, we will create **two groups of parameters/weights**, one for the newly initialized layer and the other for the rest of the network. We will then assign two distinct learning rates accordingly."
      ],
      "metadata": {
        "id": "6z4MwLq2UlqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(model, lr, wd, momentum):\n",
        "  \n",
        "  # we will create two groups of weights, one for the newly initialized layer\n",
        "  # and the other for rest of the layers of the network\n",
        "  \n",
        "  final_layer_weights = []\n",
        "  rest_of_the_net_weights = []\n",
        "  \n",
        "  # iterate through the layers of the network\n",
        "  for name, param in model.named_parameters():\n",
        "    if name.startswith('classifier.6'):\n",
        "      final_layer_weights.append(param)\n",
        "    else:\n",
        "      rest_of_the_net_weights.append(param)\n",
        "  \n",
        "  # assign the distinct learning rates to each group of parameters\n",
        "  optimizer = torch.optim.SGD([\n",
        "      {'params': rest_of_the_net_weights},\n",
        "      {'params': final_layer_weights, 'lr': lr}\n",
        "  ], lr=lr / 10, weight_decay=wd, momentum=momentum)\n",
        "  \n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "eQhWdn5IUkEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and test steps\n",
        "Similary to the previous sessions, let's now define our loops."
      ],
      "metadata": {
        "id": "19s1HB0fVhjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(net, data_loader, optimizer, cost_function, device='cuda'):\n",
        "\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  # set the network to training mode: particularly important when using dropout!\n",
        "  net.train() \n",
        "\n",
        "  # iterate over the training set\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "\n",
        "    # load data into GPU\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "      \n",
        "    # forward pass\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # loss computation\n",
        "    loss = cost_function(outputs,targets)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # parameters update\n",
        "    optimizer.step()\n",
        "    \n",
        "    # gradients reset\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # fetch prediction and loss value\n",
        "    samples += inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(dim=1) # max() returns (maximum_value, index_of_maximum_value)\n",
        "\n",
        "    # compute training accuracy\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "def test_step(net, data_loader, cost_function, device='cuda'):\n",
        "\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  # set the network to evaluation mode\n",
        "  net.eval() \n",
        "\n",
        "  # disable gradient computation (we are only testing, we do not want our model to be modified in this step!)\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # iterate over the test set\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      \n",
        "      # load data into GPU\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "        \n",
        "      # forward pass\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      # loss computation\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      # fetch prediction and loss value\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = outputs.max(1)\n",
        "\n",
        "      # compute accuracy\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ],
      "metadata": {
        "id": "CY3KOJkAVemn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put it together\n",
        "As usual, we will wrap our pipeline in a main function which takes care of initializing all our components and hyperparameters, performing a loop over multiple epochs and logging the results."
      ],
      "metadata": {
        "id": "HU-EFbS3V9At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Input arguments\n",
        "  batch_size: Size of a mini-batch\n",
        "  device: GPU where you want to train your network\n",
        "  weight_decay: Weight decay co-efficient for regularization of weights\n",
        "  momentum: Momentum for SGD optimizer\n",
        "  epochs: Number of epochs for training the network\n",
        "  num_classes: Number of classes in your dataset\n",
        "  visualization_name: Name of the visualization folder\n",
        "  img_root: The root folder of images\n",
        "'''\n",
        "\n",
        "def main(batch_size=128, \n",
        "         device='cuda:0', \n",
        "         learning_rate=0.001, \n",
        "         weight_decay=0.000001, \n",
        "         momentum=0.9, \n",
        "         epochs=50, \n",
        "         num_classes=65, \n",
        "         visualization_name='alexnet_sgd', \n",
        "         img_root=None):\n",
        "  \n",
        "  writer = SummaryWriter(log_dir=\"runs/exp1\")\n",
        "\n",
        "  # instantiates dataloaders\n",
        "  train_loader, test_loader = get_data(batch_size=batch_size, img_root=img_root)\n",
        "  \n",
        "  # instantiates the model\n",
        "  net = initialize_alexnet(num_classes=num_classes).to(device)\n",
        "  \n",
        "  # instantiates the optimizer\n",
        "  optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "  \n",
        "  # instantiates the cost function\n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  # perform a preliminar step\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test_step(net, train_loader, optimizer, cost_function)\n",
        "  test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "  \n",
        "  # add values to logger\n",
        "  writer.add_scalar('Loss/train_loss', train_loss, 0)\n",
        "  writer.add_scalar('Loss/test_loss', test_loss, 0)\n",
        "  writer.add_scalar('Accuracy/train_accuracy', train_accuracy, 0)\n",
        "  writer.add_scalar('Accuracy/test_accuracy', test_accuracy, 0)\n",
        "\n",
        "  # range over the number of epochs\n",
        "  for e in range(epochs):\n",
        "    train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function)\n",
        "    test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "    \n",
        "    # add values to logger\n",
        "    writer.add_scalar('Loss/train_loss', train_loss, e + 1)\n",
        "    writer.add_scalar('Loss/test_loss', test_loss, e + 1)\n",
        "    writer.add_scalar('Accuracy/train_accuracy', train_accuracy, e + 1)\n",
        "    writer.add_scalar('Accuracy/test_accuracy', test_accuracy, e + 1)\n",
        "\n",
        "  # perform final test step and print the final metrics\n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test_step(net, train_loader, optimizer, cost_function)\n",
        "  test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  # close the logger\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "GZGhiIDUV4Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's make it happen!"
      ],
      "metadata": {
        "id": "XBrDFNUSWq56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(visualization_name='alexnet_sgd_0.01_RW', img_root = '/content/dataset/OfficeHomeDataset_10072016/Real World')"
      ],
      "metadata": {
        "id": "M1jyiCVeWpBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now plot the performance using Tensorboard"
      ],
      "metadata": {
        "id": "IRmN92A5Y1CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "-wh3wFFDW2Mp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}