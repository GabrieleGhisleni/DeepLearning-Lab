{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_MLPFlaw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The big flaw of MLPs\n",
        "\n",
        "Today we will experimentally show what is the **fundamental flaw** of MLPs when it comes to correctly detect visual patterns in the input data, and present it as a motivation for **convolution-based solutions**. In particular, we will compare the performance of our previously implemented MLP on the [MNIST](https://pytorch.org/vision/stable/datasets.html#mnist) dataset with the performance on a **translated version** of the same data."
      ],
      "metadata": {
        "id": "HVQuq23Q9Hyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, we start by importing the modules that we need."
      ],
      "metadata": {
        "id": "TLLNs9dy9pAM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIZU13zsxAM0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation function\n",
        "In this block we are going to define and implement the method which will take care of **transforming** the items in our dataset in such a way to obtain **visually translated** versions of the input digits."
      ],
      "metadata": {
        "id": "ykdTcp1M99JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_translation_transform():\n",
        "  '''\n",
        "  Creates a transformation that pads the original input so that the\n",
        "  digit is not centered in the image\n",
        "  '''\n",
        "  def padding(x):\n",
        "      pad_size = 28\n",
        "      left_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
        "      top_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
        "      return F.pad(x, (left_padding, \n",
        "                       pad_size - left_padding, \n",
        "                       top_padding, \n",
        "                       pad_size - top_padding), \"constant\", 0)\n",
        "   \n",
        "  translation_transform = list()\n",
        "  translation_transform.append(T.ToTensor())\n",
        "  translation_transform.append(T.Lambda(lambda x: padding(x)))\n",
        "  translation_transform.append(T.Lambda(lambda x: x.repeat(3, 1, 1)))\n",
        "  translation_transform = T.Compose(translation_transform)\n",
        "  \n",
        "  return translation_transform"
      ],
      "metadata": {
        "id": "jtyBrLjJxNNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "In this block we want to create a method that returns the required **dataloading utility** over our dataset, in such a way to **choose** whether we want to apply the translation or not by means of a parameter."
      ],
      "metadata": {
        "id": "obE13C39_2g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_for_visualization(batch_size, translate=False): \n",
        "  \n",
        "  if not translate:\n",
        "    # image transformation that appends 14 pixels on each side of a digit\n",
        "    transform = list()\n",
        "    transform.append(T.ToTensor())\n",
        "    transform.append(T.Lambda(lambda x: F.pad(x, (14, 14, 14, 14), \"constant\", 0)))\n",
        "    transform = T.Compose(transform)\n",
        "  else:\n",
        "    # applies random translations to images\n",
        "    transform = create_translation_transform()\n",
        "\n",
        "  # load data\n",
        "  full_training_data = torchvision.datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
        "\n",
        "  # initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(full_training_data, batch_size, shuffle=True)\n",
        "  \n",
        "  return train_loader"
      ],
      "metadata": {
        "id": "JO_my8CC0Uhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization\n",
        "We want to obtain a visual representation that allows us to **compare** the original digits of the dataset with their translated version."
      ],
      "metadata": {
        "id": "qV2v8x0ZBG8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a bunch of training images for visualization over the original and \n",
        "# translated dataset, respectively\n",
        "train_loader = get_data_for_visualization(256, translate=False)\n",
        "train_loader_translated = get_data_for_visualization(256, translate=True)\n",
        "\n",
        "# define iterators over both datasets\n",
        "train_iter, train_iter_translated = iter(train_loader), iter(train_loader_translated)\n",
        "\n",
        "# get labels of original digits\n",
        "data, labels = next(train_iter)\n",
        "\n",
        "# get labels of translated digits\n",
        "data_translated, labels_translated = next(train_iter_translated)\n",
        "\n",
        "# the label of the digit you want to visualize\n",
        "digit_label = 8\n",
        "\n",
        "# get first 9 indices of the chosen digit for non-translated digits\n",
        "get_idx = (labels == digit_label).nonzero().squeeze(-1)[0:9]\n",
        "\n",
        "# get first 9 indices of the chosen digit for translated digits\n",
        "get_idx_translated = (labels_translated == digit_label).nonzero().squeeze(-1)[0:9]\n",
        "\n",
        "# get the data and labels for the chosen digit\n",
        "get_data, get_labels = data[get_idx, :, :, :], labels[get_idx]\n",
        "get_data_translated, get_labels_translated = data_translated[get_idx_translated, :, :, :], \\\n",
        "                                             labels_translated[get_idx_translated]\n",
        "\n",
        "\n",
        "### visualize the plots inline, both for original and translated digits ###\n",
        "\n",
        "# original\n",
        "display_grid = torchvision.utils.make_grid(get_data, nrow=3, padding=2, pad_value=1)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(display_grid.numpy().transpose(1,2,0))\n",
        "plt.axis('off')\n",
        "plt.title('Centered Digits')\n",
        "\n",
        "# translated\n",
        "display_grid_translated = torchvision.utils.make_grid(get_data_translated, nrow=3, padding=2, pad_value=1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(display_grid_translated.numpy().transpose(1,2,0))\n",
        "plt.axis('off')\n",
        "plt.title('Translated Digits')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nQmB7Kir8Y56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP architecture\n",
        "We will use the same architecture that we have discussed and implemented in the previous lab session"
      ],
      "metadata": {
        "id": "Az-K8L5oBu3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyFirstNetwork(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "\n",
        "    # initialize the function\n",
        "    super(MyFirstNetwork, self).__init__()\n",
        "    \n",
        "    # first linear layer (input)\n",
        "    self.input_to_hidden = torch.nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "    # activation function\n",
        "    self.activation = torch.nn.Sigmoid()\n",
        "\n",
        "    # second linear layer (output)\n",
        "    self.hidden_to_output = torch.nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    # initialize bias\n",
        "    self.input_to_hidden.bias.data.fill_(0.)\n",
        "    self.hidden_to_output.bias.data.fill_(0.)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # puts the output in (batch_size, input_dim) format\n",
        "    x = x.view(x.shape[0],-1)\n",
        "\n",
        "    # forward the input through the layers\n",
        "    x = self.input_to_hidden(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.hidden_to_output(x)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "j1CzNOKhCe3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost function and optimizer\n",
        "Also for these two components, we stick to those employed in the previous lab."
      ],
      "metadata": {
        "id": "APuCISvfCrP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function\n",
        "\n",
        "def get_optimizer(net, lr, wd, momentum):\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "ur0qy-JBChFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and test steps\n",
        "We already know the drill!"
      ],
      "metadata": {
        "id": "wGxHI0uxFCI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(net, data_loader, optimizer, cost_function, device='cuda'):\n",
        "\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  # set the network to training mode\n",
        "  net.train() \n",
        "\n",
        "  # iterate over the training set\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "\n",
        "    # load data into GPU\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "      \n",
        "    # forward pass\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # loss computation\n",
        "    loss = cost_function(outputs,targets)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # parameters update\n",
        "    optimizer.step()\n",
        "    \n",
        "    # gradients reset\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # fetch prediction and loss value\n",
        "    samples += inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(dim=1) # max() returns (maximum_value, index_of_maximum_value)\n",
        "\n",
        "    # compute training accuracy\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "def test_step(net, data_loader, cost_function, device='cuda'):\n",
        "\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  # set the network to evaluation mode\n",
        "  net.eval() \n",
        "\n",
        "  # disable gradient computation (we are only testing, we do not want our model to be modified in this step!)\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # iterate over the test set\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      \n",
        "      # load data into GPU\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "        \n",
        "      # forward pass\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      # loss computation\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      # fetch prediction and loss value\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = outputs.max(1)\n",
        "\n",
        "      # compute accuracy\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ],
      "metadata": {
        "id": "hWKua57qE79H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "Let us now define a compact method to return the dataloaders that we need to perform our experiment."
      ],
      "metadata": {
        "id": "jJzgp_pOF-GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(batch_size, test_batch_size=128, translate=False): \n",
        "  \n",
        "  # define the transformations (same way as before)\n",
        "  if translate:\n",
        "    def padding(x):\n",
        "        pad_size = 28\n",
        "        left_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
        "        top_padding = torch.randint(low=0, high=pad_size, size=(1,))\n",
        "        return F.pad(x, (left_padding, \n",
        "                         pad_size - left_padding, \n",
        "                         top_padding, \n",
        "                         pad_size - top_padding), \"constant\", 0)\n",
        "\n",
        "    transform = list()\n",
        "    transform.append(T.ToTensor())\n",
        "    transform.append(T.Lambda(lambda x: padding(x)))\n",
        "    transform = T.Compose(transform)\n",
        "  else:\n",
        "    transform = list()\n",
        "    transform.append(T.ToTensor())\n",
        "    transform.append(T.Lambda(lambda x: F.pad(x, (14, 14, 14, 14), \"constant\", 0)))\n",
        "    transform = T.Compose(transform)\n",
        "    \n",
        "  # load data\n",
        "  full_training_data = torchvision.datasets.MNIST('./data', train=True, transform=transform, download=True) \n",
        "  test_data = torchvision.datasets.MNIST('./data', train=False, transform=transform, download=True) \n",
        "  \n",
        "  # split into training and validation sets\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.5+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "\n",
        "  # initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(validation_data, test_batch_size, shuffle=False)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n",
        "  \n",
        "  return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "AwVJu7teF5YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main function\n",
        "Let's now define our wrapper to actually train and evaluate our model"
      ],
      "metadata": {
        "id": "8G6-GK5P0eUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Input arguments:\n",
        "  batch_size: the size of a mini-batch that is used for training\n",
        "  input_dim: flattened size of the input image vector\n",
        "  hidden_dim: number of hidden neurons in the network\n",
        "  output_dim: the number of output neurons\n",
        "  device: GPU where you want to train your network\n",
        "  learning_rate: learning rate for the optimizer\n",
        "  weight_decay: weight decay coefficient for regularization of weights\n",
        "  momentum: momentum for SGD optimizer\n",
        "  epochs: number of epochs for training the network\n",
        "  translate: whether to translate the images that are fed to the network\n",
        "  visualization_name: name of the graph for visualizing in tensorboards\n",
        "                      (always remember to use an unique visualization_name\n",
        "                       for each training, otherwise it will mess up the visualization!)\n",
        "'''\n",
        "\n",
        "def main_MLP(batch_size=64, input_dim=56*56, hidden_dim=100, output_dim=10, device='cuda:0', \n",
        "             learning_rate=0.01, weight_decay=0.000001, momentum=0.9, epochs=50, \n",
        "             translate=False, visualization_name='centered'):\n",
        "  \n",
        "  # creates a logger for the experiment\n",
        "  writer = SummaryWriter(log_dir=f\"runs/{visualization_name}\")\n",
        "\n",
        "  # get dataloaders\n",
        "  train_loader, val_loader, test_loader = get_data(batch_size=batch_size, translate=translate)\n",
        "  \n",
        "  # correctly set the device\n",
        "  device = torch.device(device)\n",
        "  \n",
        "  # instantiate the model and send it to the device\n",
        "  net = MyFirstNetwork(input_dim, hidden_dim, output_dim).to(device)\n",
        "  \n",
        "  # instantiate optimizer & cost function\n",
        "  optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  # perform a single test step beforehand and print metrics\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test_step(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test_step(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "  \n",
        "  # add values to logger\n",
        "  writer.add_scalar('Loss/train_loss', train_loss, 0)\n",
        "  writer.add_scalar('Loss/val_loss', val_loss, 0)\n",
        "  writer.add_scalar('Accuracy/train_accuracy', train_accuracy, 0)\n",
        "  writer.add_scalar('Accuracy/val_accuracy', val_accuracy, 0)\n",
        "  \n",
        "  # iterate over the epochs number\n",
        "  for e in range(epochs):\n",
        "    train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function)\n",
        "    val_loss, val_accuracy = test_step(net, val_loader, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "    \n",
        "    # add values to logger\n",
        "    writer.add_scalar('Loss/train_loss', train_loss, e + 1)\n",
        "    writer.add_scalar('Loss/val_loss', val_loss, e + 1)\n",
        "    writer.add_scalar('Accuracy/train_accuracy', train_accuracy, e + 1)\n",
        "    writer.add_scalar('Accuracy/val_accuracy', val_accuracy, e + 1)\n",
        "\n",
        "  # compute and print final metrics\n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test_step(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test_step(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test_step(net, test_loader, cost_function)\n",
        "  \n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  # close the logger\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "mqJ1opqbGDcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run!\n",
        "Let's first run the MLP on the original dataset"
      ],
      "metadata": {
        "id": "ZjZEdZFe1beV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r runs\n",
        "main_MLP(translate=False, visualization_name='centered')"
      ],
      "metadata": {
        "id": "WsJfbfwi1hqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now run it on the translated version"
      ],
      "metadata": {
        "id": "WxbZNGMY46Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_MLP(translate=True, visualization_name='translated')"
      ],
      "metadata": {
        "id": "j_vRsdNO402P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And see the results!"
      ],
      "metadata": {
        "id": "QHn5waoY8WS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "VgCiuS5ZGFZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}